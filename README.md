# LLM Compression Papers 
## Introduction
Welcome to the LLM Compression  Papers repository! This repository is dedicated to the collection and discussion of academic and industry papers focused on the compression techniques for large language models (LLMs). As the capabilities of LLMs continue to expand, so does their size and complexity. Consequently, efficient compression methods have become crucial for making these models more accessible and practical for real-world applications. 

## Network Pruning


## Quantization  


## Knowledge Distillation


## Fusion

